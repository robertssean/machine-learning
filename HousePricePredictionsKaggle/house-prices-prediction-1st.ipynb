{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-21T09:35:29.875773Z","iopub.execute_input":"2021-10-21T09:35:29.876207Z","iopub.status.idle":"2021-10-21T09:35:29.915190Z","shell.execute_reply.started":"2021-10-21T09:35:29.876107Z","shell.execute_reply":"2021-10-21T09:35:29.914199Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# reading the dataset (training dataset)\ndf_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:35:29.917648Z","iopub.execute_input":"2021-10-21T09:35:29.918036Z","iopub.status.idle":"2021-10-21T09:35:29.995702Z","shell.execute_reply.started":"2021-10-21T09:35:29.917987Z","shell.execute_reply":"2021-10-21T09:35:29.994673Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# what is the prediction target? \ny = df_train.SalePrice","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:35:29.997723Z","iopub.execute_input":"2021-10-21T09:35:29.998426Z","iopub.status.idle":"2021-10-21T09:35:30.007331Z","shell.execute_reply.started":"2021-10-21T09:35:29.998375Z","shell.execute_reply":"2021-10-21T09:35:30.005955Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_train.describe(include=['number']).loc[['min','max','mean']].T.sort_values('max')","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:35:30.009745Z","iopub.execute_input":"2021-10-21T09:35:30.010265Z","iopub.status.idle":"2021-10-21T09:35:30.121523Z","shell.execute_reply.started":"2021-10-21T09:35:30.010227Z","shell.execute_reply":"2021-10-21T09:35:30.120673Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# what are the features\n# we'll choose the number of bedrooms because that was a big predictor of price for the ml tutorial and also 'LotFrontage'\n\nfeatures = ['BedroomAbvGr']\n\nX = df_train[features]\n\nX.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:35:30.122794Z","iopub.execute_input":"2021-10-21T09:35:30.123057Z","iopub.status.idle":"2021-10-21T09:35:30.140401Z","shell.execute_reply.started":"2021-10-21T09:35:30.123025Z","shell.execute_reply":"2021-10-21T09:35:30.139482Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#if we wanted to filter out the 0 data, we would use:\n#filtered_df_train = df_train.dropna(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:35:30.141911Z","iopub.execute_input":"2021-10-21T09:35:30.142169Z","iopub.status.idle":"2021-10-21T09:35:30.150958Z","shell.execute_reply.started":"2021-10-21T09:35:30.142139Z","shell.execute_reply":"2021-10-21T09:35:30.150054Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Steps to building a model\n* define - what type of model?\n* fit - find the patterns\n* predict - predict using the test data\n* evaluate - the accuracy of the model e.g. MAE","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n#define - DecisionTreeRegressor\ndt_house_price_model = DecisionTreeRegressor(random_state=1)\n#fit \ndt_house_price_model.fit(X, y)\n#predict\npredictions = dt_house_price_model.predict(X)\nprint(mean_absolute_error(y, predictions))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:52:26.004909Z","iopub.execute_input":"2021-10-21T09:52:26.005267Z","iopub.status.idle":"2021-10-21T09:52:26.021542Z","shell.execute_reply.started":"2021-10-21T09:52:26.005233Z","shell.execute_reply":"2021-10-21T09:52:26.020326Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\n\nfrom sklearn.model_selection import train_test_split\n\n\nfrom sklearn.metrics import mean_absolute_error\nX_train, val_X, y_train, val_y = train_test_split(X, y, random_state=0)\n#fit\ndt_house_price_model_2 = DecisionTreeRegressor()\n\ndt_house_price_model_2.fit(X_train, y_train)\n\nval_predictions = dt_house_price_model_2.predict(val_X)\nprint(mean_absolute_error(val_y, val_predictions))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:52:39.054673Z","iopub.execute_input":"2021-10-21T09:52:39.054988Z","iopub.status.idle":"2021-10-21T09:52:39.069797Z","shell.execute_reply.started":"2021-10-21T09:52:39.054958Z","shell.execute_reply":"2021-10-21T09:52:39.068789Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Is it clear that splitting the training data using 'train_test_split' and creating a model on the full training data, there is little difference in the MAE for a DecisionTreeRegressor(). \n\nWhat about for a RandomForestRegressor()? ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n#define - RandomForestRegressor\nrf_house_price_model = RandomForestRegressor(random_state=1)\n#fit \nrf_house_price_model.fit(X, y)\n#predict\nrf_predictions = rf_house_price_model.predict(X)\nprint(mean_absolute_error(y, rf_predictions))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:54:41.454029Z","iopub.execute_input":"2021-10-21T09:54:41.454326Z","iopub.status.idle":"2021-10-21T09:54:41.682008Z","shell.execute_reply.started":"2021-10-21T09:54:41.454296Z","shell.execute_reply":"2021-10-21T09:54:41.681019Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\n#fit\nrf_house_price_model_2 = RandomForestRegressor(random_state=1)\n\nrf_house_price_model_2.fit(X_train, y_train)\n\nrf_val_predictions = rf_house_price_model_2.predict(val_X)\nprint(mean_absolute_error(val_y, rf_val_predictions))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:56:46.709031Z","iopub.execute_input":"2021-10-21T09:56:46.710135Z","iopub.status.idle":"2021-10-21T09:56:46.900581Z","shell.execute_reply.started":"2021-10-21T09:56:46.710081Z","shell.execute_reply":"2021-10-21T09:56:46.899376Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(house_price_model.predict(X.head()))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:35:31.396005Z","iopub.execute_input":"2021-10-21T09:35:31.396645Z","iopub.status.idle":"2021-10-21T09:35:31.408386Z","shell.execute_reply.started":"2021-10-21T09:35:31.396610Z","shell.execute_reply":"2021-10-21T09:35:31.407641Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(house_price_model_2.predict(X.head()))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:38:06.061481Z","iopub.execute_input":"2021-10-21T09:38:06.062660Z","iopub.status.idle":"2021-10-21T09:38:06.070200Z","shell.execute_reply.started":"2021-10-21T09:38:06.062584Z","shell.execute_reply":"2021-10-21T09:38:06.069298Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:35:31.409667Z","iopub.execute_input":"2021-10-21T09:35:31.410853Z","iopub.status.idle":"2021-10-21T09:35:31.422174Z","shell.execute_reply.started":"2021-10-21T09:35:31.410782Z","shell.execute_reply":"2021-10-21T09:35:31.421226Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"To consider: \n\n1. What about adding more features and seeing if it increases the accuracy of the model? \n2. cleaning the data? ","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\n\n\n\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\ntest_X = df_test[features]\n\ntest_preds = house_price_model.predict(test_X)\n\noutput = pd.DataFrame({'Id': df_test.Id,\n                       'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T09:35:31.424002Z","iopub.execute_input":"2021-10-21T09:35:31.424966Z","iopub.status.idle":"2021-10-21T09:35:31.489643Z","shell.execute_reply.started":"2021-10-21T09:35:31.424917Z","shell.execute_reply":"2021-10-21T09:35:31.488333Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"This submission produced a score of:\n\n> Public Score\n> \n> 0.41714","metadata":{}}]}